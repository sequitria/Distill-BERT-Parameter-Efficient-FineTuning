{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install evaluate\n!pip install -q evaluate\n\n# 2. THE FIX: Force install this specific version of protobuf\n!pip install -q \"protobuf==3.20.3\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:33:32.089928Z","iopub.execute_input":"2025-11-29T20:33:32.090096Z","iopub.status.idle":"2025-11-29T20:33:44.563939Z","shell.execute_reply.started":"2025-11-29T20:33:32.090080Z","shell.execute_reply":"2025-11-29T20:33:44.563108Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport pandas as pd\nimport gc\nimport time\n\n# Import Hugging Face libraries\nimport evaluate\nfrom datasets import load_dataset, Dataset, DatasetDict, IterableDataset, IterableDatasetDict\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, EvalPrediction\nfrom peft import LoraConfig, TaskType, get_peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:33:44.565632Z","iopub.execute_input":"2025-11-29T20:33:44.565841Z","iopub.status.idle":"2025-11-29T20:34:13.221929Z","shell.execute_reply.started":"2025-11-29T20:33:44.565817Z","shell.execute_reply":"2025-11-29T20:34:13.221342Z"}},"outputs":[{"name":"stderr","text":"2025-11-29 20:33:55.673886: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764448435.863257      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764448435.913878      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import the Python types\nfrom typing import List, Dict, Any, Tuple, cast, Optional\n\nfrom dataclasses import dataclass, asdict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:13.222664Z","iopub.execute_input":"2025-11-29T20:34:13.223230Z","iopub.status.idle":"2025-11-29T20:34:13.227006Z","shell.execute_reply.started":"2025-11-29T20:34:13.223210Z","shell.execute_reply":"2025-11-29T20:34:13.226316Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"SEED = 42\nTRAIN_SAMPLE_SIZE = 3000\nTOTAL_TRIALS = 20\nNUM_LABELS = 6\nMAX_LENGTH = 128\nMODEL = \"distilbert-base-uncased\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:13.227759Z","iopub.execute_input":"2025-11-29T20:34:13.227970Z","iopub.status.idle":"2025-11-29T20:34:13.247704Z","shell.execute_reply.started":"2025-11-29T20:34:13.227955Z","shell.execute_reply":"2025-11-29T20:34:13.247019Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def set_global_seed(seed: int):\n  \"\"\"\n  Set the global seed for reproducibility.\n  \"\"\"\n  random.seed(seed)\n  np.random.seed(seed)\n  torch.manual_seed(seed)\n\n  # Check if CUDA GPU is available\n  if torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:13.248411Z","iopub.execute_input":"2025-11-29T20:34:13.248667Z","iopub.status.idle":"2025-11-29T20:34:13.262562Z","shell.execute_reply.started":"2025-11-29T20:34:13.248646Z","shell.execute_reply":"2025-11-29T20:34:13.261827Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"set_global_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:13.263383Z","iopub.execute_input":"2025-11-29T20:34:13.263960Z","iopub.status.idle":"2025-11-29T20:34:13.281467Z","shell.execute_reply.started":"2025-11-29T20:34:13.263934Z","shell.execute_reply":"2025-11-29T20:34:13.280882Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"@dataclass(frozen=True, order=True)\nclass LoraHyperparameters:\n  learning_rate: float\n  warmup_ratio: float\n  rank: int\n  alpha: int\n  dropout: float\n  target_modules: List[str]\n\n  @staticmethod # The 'generate_random_hyperparameters' doesn't take an instance of 'self', hence why we use '@staticmethod'\n  def generate_random_hyperparameters() -> 'LoraHyperparameters':\n\n    # Target modules: (Attention Only) OR (Attention + Feedforward)\n      # Option A: [\"q_lin\", \"v_lin\"]\n      # Option B: [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]\n    module_choice = random.choice([\"attn\", \"attn_ffn\"])\n\n    if module_choice == \"attn\":\n        target_modules = [\"q_lin\", \"v_lin\"]\n    else:\n        target_modules = [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]\n\n    min_log = np.log10(5e-6)\n    max_log = np.log10(5e-4)\n    random_log = random.uniform(min_log, max_log)\n    learning_rate = 10 ** random_log\n\n    # Return an instance of the LoraHyperparameters class\n    return LoraHyperparameters(\n      # learning_rate=random.uniform(5e-6, 5e-4), # Learning rate is a continous value\n      learning_rate=learning_rate,\n      warmup_ratio=random.choice([0.0, 0.06, 0.1]), # Warm-up ratio is a discrete value\n      rank=random.choice([2, 4, 8, 16, 24]), # LoRA rank is a continous value\n      alpha = random.choice([8, 16, 32, 64, 96]), # Alpha is a discrete value\n      dropout = random.choice([0, 0.05, 0.1, 0.2]), # Dropout is a discrete value\n      target_modules=target_modules\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:13.283685Z","iopub.execute_input":"2025-11-29T20:34:13.283947Z","iopub.status.idle":"2025-11-29T20:34:13.290834Z","shell.execute_reply.started":"2025-11-29T20:34:13.283930Z","shell.execute_reply":"2025-11-29T20:34:13.290167Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class DataManager:\n  def __init__(self, model_name: str = MODEL):\n    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n    self.dataset: Optional[Dict[str, Any]] = None\n\n  def prepare_data(self) -> Dict[str, Any]:\n    \"\"\"\n    Loads the dataset and processes it.\n    \"\"\"\n\n    # Check if the dataset is correctly loaded into the instance memory\n    if self.dataset is not None:\n        return self.dataset\n\n    print(\"Loading and processing data...\")\n\n    # Load full dataset\n    full_dataset = cast(DatasetDict, load_dataset(\"dair-ai/emotion\"))\n\n    # Use seed to ensure every run uses the SAME subset of data\n    train_subset = full_dataset[\"train\"].shuffle(seed=SEED).select(range(TRAIN_SAMPLE_SIZE))\n\n    # Private helper method for text embeddings\n    def _tokenize(examples):\n      return self.tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=MAX_LENGTH\n      )\n\n    tokenized_train_dataset = train_subset.map(_tokenize, batched=True)\n    tokenized_validation_dataset = full_dataset[\"validation\"].map(_tokenize, batched=True)\n\n    self.dataset = {\n        \"train\": tokenized_train_dataset,\n        \"validation\": tokenized_validation_dataset,\n        \"tokenizer\": self.tokenizer,\n        \"num_labels\": NUM_LABELS\n    }\n\n    print(\"Data preparation complete.\")\n\n    return self.dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:13.291400Z","iopub.execute_input":"2025-11-29T20:34:13.291582Z","iopub.status.idle":"2025-11-29T20:34:13.308751Z","shell.execute_reply.started":"2025-11-29T20:34:13.291567Z","shell.execute_reply":"2025-11-29T20:34:13.308160Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"data_manager = DataManager()\ndata_bundle = data_manager.prepare_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:13.309334Z","iopub.execute_input":"2025-11-29T20:34:13.309525Z","iopub.status.idle":"2025-11-29T20:34:22.020950Z","shell.execute_reply.started":"2025-11-29T20:34:13.309503Z","shell.execute_reply":"2025-11-29T20:34:22.020121Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3058166f7f9847dcae28fca3657064b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed5f476707bc4694ae815724b1b5b13f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09c994d06f9141b98facd3d3a9ae74a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1030375d3a645a4a4bf6bf86a90da72"}},"metadata":{}},{"name":"stdout","text":"Loading and processing data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bfda566d1d64638a8c1fad171ca3dfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/train-00000-of-00001.parquet:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6a2289585e3454c9b678d67037b5d3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/validation-00000-of-00001.parquet:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af9a4d5406f4bcba4d5138656f91d0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/test-00000-of-00001.parquet:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"003fe431e28348c3a6a6a31b863923fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ebc46be32174eb492fe6484a2010b9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b83c6b2ed3a44bab298b17e71f0a9b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60225d4e121f45e48c9c33017ee73261"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d58c58a7f00456283a03281f99ccba7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c005cfdd26e4e4c92b36a00603cada6"}},"metadata":{}},{"name":"stdout","text":"Data preparation complete.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class RandomSearchExperiment:\n  def __init__(self, data_bundle: Dict[str, Any], total_trials: int = 20):\n    self.data = data_bundle\n    self.total_trials = total_trials\n    self.results: List[Dict[str, Any]] = []\n    self.metric = evaluate.load(\"accuracy\")\n\n  def _compute_metrics(self, eval_pred: EvalPrediction) -> Dict[str, float]:\n    \"\"\"\n    Calculates accuracy during training.\n    \"\"\"\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n\n    result = self.metric.compute(predictions=predictions, references=labels)\n\n    return cast(Dict[str, float], result)\n\n  def _cleanup_memory(self, model, trainer):\n    \"\"\"\n    Forcefully clears GPU memory.\n    \"\"\"\n    del model\n    del trainer\n    torch.cuda.empty_cache()\n    gc.collect()\n\n  def run_single_trial(self, trial_id: int, params: LoraHyperparameters, seed: Optional[int] = None) -> Tuple[float, float]:\n    \"\"\"\n    Executes one training run with specific hyperparameters.\n    \"\"\"\n    print(f\"\\n[Trial {trial_id}/{self.total_trials}] Starting...\")\n    print(f\"   Params: Rank={params.rank}, Alpha={params.alpha}, LR={params.learning_rate:.2e}\")\n\n    # # Add 'trial_id' to the 'SEED' to ensure each trial is unique\n    # current_seed = SEED + trial_id\n\n    if seed is not None:\n      current_seed = seed\n    else:\n      current_seed = SEED + trial_id\n\n    # Initialize the base model\n    model = AutoModelForSequenceClassification.from_pretrained(\n      MODEL,\n      num_labels=self.data[\"num_labels\"]\n    )\n\n    # LoRA configuration\n    peft_config = LoraConfig(\n      task_type=TaskType.SEQ_CLS,\n      r=params.rank,\n      lora_alpha=params.alpha,\n      lora_dropout=params.dropout,\n      target_modules=params.target_modules\n    )\n\n    model = get_peft_model(model, peft_config)\n\n    args = TrainingArguments(\n      output_dir=f\"./results/trial_{trial_id}\",\n      learning_rate=params.learning_rate,\n      per_device_train_batch_size=16,\n      per_device_eval_batch_size=16,\n      num_train_epochs=3,\n      warmup_ratio=params.warmup_ratio,\n      weight_decay=0.01,\n      eval_strategy=\"epoch\", # Updated from 'evaluation_strategy'\n      save_strategy=\"no\", # Don't save checkpoints (saves disk space)\n      logging_strategy=\"epoch\",\n      seed=current_seed,\n      report_to=\"none\", # Disable WANDB\n      load_best_model_at_end=False,\n      optim=\"adamw_torch\"\n    )\n\n    # Initialize the Trainer\n    trainer = Trainer(\n      model=model,\n      args=args,\n      train_dataset=self.data[\"train\"],\n      eval_dataset=self.data[\"validation\"],\n      data_collator=DataCollatorWithPadding(tokenizer=self.data[\"tokenizer\"]),\n      compute_metrics=self._compute_metrics\n    )\n\n    start_time = time.time()\n\n    # Train and Evaluate\n    trainer.train()\n    eval_results = trainer.evaluate()\n\n    end_time = time.time()\n    trial_duration = end_time - start_time\n\n    accuracy = eval_results[\"eval_accuracy\"]\n\n    print(f\"   [Trial {trial_id}] Complete. Accuracy: {accuracy:.4%} | Time: {trial_duration:.2f}s\")\n\n    # Cleanup the memory\n    self._cleanup_memory(model, trainer)\n\n    return accuracy, trial_duration\n\n  def verify_top_trials(self, top_k: int = 5, seeds: List[int] = [42, 43, 44]):\n    # Check if there are any results\n    if not self.results:\n      print(\"No results found in memory. Please run experiment first.\")\n      return\n\n    print(f\"\\n\" + \"=\"*40)\n    print(f\"STARTING ROBUSTNESS VERIFICATION (Top {top_k} Models)\")\n    print(\"=\"*40)\n\n    # Sort the results by accuracy in descending order and slice the top K\n    sorted_results = sorted(self.results, key=lambda x: x[\"accuracy\"], reverse=True)\n    top_k_results = sorted_results[:top_k]\n\n    robustness_data: List[Dict[str, Any]] = []\n\n    for i, trial in enumerate(top_k_results, start=1):\n      trial_id = trial[\"trial_id\"]\n      original_accuracy = trial[\"accuracy\"] # Renamed to avoid confusion\n      \n      print(f\"\\n>>> Verifying Rank {i}: Trial {trial_id} (Original Acc: {original_accuracy:.4%})\")\n\n      params = LoraHyperparameters(\n          learning_rate=trial[\"learning_rate\"],\n          warmup_ratio=trial[\"warmup_ratio\"],\n          rank=trial[\"rank\"],\n          alpha=trial[\"alpha\"],\n          dropout=trial[\"dropout\"],\n          target_modules=trial[\"target_modules\"]\n      )\n\n      current_accuracies = []\n\n      for seed in seeds:\n        # Fixed Argument passing syntax here\n        new_acc, _ = self.run_single_trial(trial_id, params, seed=seed)\n        current_accuracies.append(new_acc)\n\n        # Explicit garbage collection\n        torch.cuda.empty_cache()\n        gc.collect()\n      \n      mean_accuracy = np.mean(current_accuracies)\n      std_accuracy = np.std(current_accuracies)\n      \n      print(f\"    -> Result: {mean_accuracy:.4%} ± {std_accuracy:.4%}\")\n\n      entry = {\n          \"trial_id\": trial_id,\n          \"original_accuracy\": original_accuracy,\n          \"mean_accuracy\": mean_accuracy,\n          \"std_accuracy\": std_accuracy,\n          \"all_seed_accuracies\": current_accuracies\n      }\n\n      entry.update(asdict(params))\n      robustness_data.append(entry)\n\n    df_robust = pd.DataFrame(robustness_data)\n    filename = \"robustness_verification_results.csv\"\n    df_robust.to_csv(filename, index=False)\n\n    print(f\"\\nRobustness verification complete. Saved to {filename}\")\n\n\n  def run_experiment(self):\n    \"\"\"\n    Main loop to execute the random search.\n    \"\"\"\n    print(f\"Starting Random Search for {self.total_trials} trials...\")\n\n    for i in range(self.total_trials):\n      trial_id = i + 1\n\n      try:\n        # Generate the random hyperparameters\n        params = LoraHyperparameters.generate_random_hyperparameters()\n\n        # Run the current trial\n        accuracy, trial_duration = self.run_single_trial(trial_id=trial_id, params=params)\n\n        # Log the current result\n        result_entry = {\n            \"trial_id\": trial_id,\n            \"accuracy\": accuracy,\n            \"trial_duration_in_seconds\": trial_duration\n        }\n\n        # Flatten parameters into the dict for easier CSV saving\n        result_entry.update(asdict(params))\n\n        self.results.append(result_entry)\n\n      except Exception as e:\n        print(f\"!!! CRITICAL ERROR in Trial {trial_id}: {e}\")\n\n        # Clean the memory\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    print(\"\\nExperiment Completed.\")\n\n  def save_results(self, filename=\"random_search_results.csv\"):\n    \"\"\"\n    Saves results to CSV and prints summary stats.\n    \"\"\"\n    if not self.results:\n      print(\"No results to save.\")\n      return\n\n    df = pd.DataFrame(self.results)\n\n    # Summary\n    best_idx = df['accuracy'].idxmax()\n    best_row = df.loc[best_idx]\n\n    best_accuracy = best_row['accuracy'].item()\n    best_trial_id = int(best_row['trial_id'].item())\n\n    print(\"\\n\" + \"=\"*40)\n    print(\"RESULTS SUMMARY\")\n    print(\"=\"*40)\n    print(f\"Best Accuracy: {best_accuracy:.4%} (Trial {best_trial_id})\")\n    print(f\"Mean Accuracy: {df['accuracy'].mean():.4%}\")\n    print(f\"Std Dev      : {df['accuracy'].std():.4%}\")\n\n    # Export\n    df.to_csv(filename, index=False)\n\n    print(f\"Results saved to {filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:22.021882Z","iopub.execute_input":"2025-11-29T20:34:22.022110Z","iopub.status.idle":"2025-11-29T20:34:22.041029Z","shell.execute_reply.started":"2025-11-29T20:34:22.022093Z","shell.execute_reply":"2025-11-29T20:34:22.040332Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Create the Experiment\nexperiment = RandomSearchExperiment(data_bundle, total_trials=TOTAL_TRIALS)\n\nstart_experiment_time = time.time()\n\n# Run the full experiment of 20 trials\nexperiment.run_experiment()\n\nend_experiment_time = time.time()\n\ntotal_duration = end_experiment_time - start_experiment_time\n\nprint(f\"Total time taken to complete 20 experiments: {str(total_duration)} seconds\")\n\n# Save the results from running the full experiment\nexperiment.save_results()\n\nexperiment.verify_top_trials(top_k=5, seeds=[42, 43, 44])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T20:34:22.041825Z","iopub.execute_input":"2025-11-29T20:34:22.042166Z","iopub.status.idle":"2025-11-29T21:11:38.141621Z","shell.execute_reply.started":"2025-11-29T20:34:22.042140Z","shell.execute_reply":"2025-11-29T21:11:38.140926Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8d1ebce317b43878b028bce4aaba245"}},"metadata":{}},{"name":"stdout","text":"Starting Random Search for 20 trials...\n\n[Trial 1/20] Starting...\n   Params: Rank=4, Alpha=16, LR=5.61e-06\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5380a5a844434045bb7c1be36e431977"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.731900</td>\n      <td>1.667208</td>\n      <td>0.362500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.638200</td>\n      <td>1.613737</td>\n      <td>0.352500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.604400</td>\n      <td>1.600600</td>\n      <td>0.352000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 1] Complete. Accuracy: 35.2000% | Time: 60.49s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 2/20] Starting...\n   Params: Rank=16, Alpha=32, LR=1.87e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.628300</td>\n      <td>1.547182</td>\n      <td>0.474000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.480900</td>\n      <td>1.426857</td>\n      <td>0.518000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.364800</td>\n      <td>1.352590</td>\n      <td>0.531500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 2] Complete. Accuracy: 53.1500% | Time: 58.98s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 3/20] Starting...\n   Params: Rank=2, Alpha=16, LR=5.48e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.467100</td>\n      <td>1.144122</td>\n      <td>0.560000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.012600</td>\n      <td>0.938374</td>\n      <td>0.664000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.874300</td>\n      <td>0.883662</td>\n      <td>0.677500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 3] Complete. Accuracy: 67.7500% | Time: 68.36s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 4/20] Starting...\n   Params: Rank=2, Alpha=32, LR=3.42e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.509100</td>\n      <td>1.227870</td>\n      <td>0.551000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.133600</td>\n      <td>1.056275</td>\n      <td>0.621000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.016700</td>\n      <td>1.012142</td>\n      <td>0.645500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 4] Complete. Accuracy: 64.5500% | Time: 68.49s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 5/20] Starting...\n   Params: Rank=24, Alpha=16, LR=3.15e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.604200</td>\n      <td>1.512941</td>\n      <td>0.448000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.366500</td>\n      <td>1.246972</td>\n      <td>0.536500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.201500</td>\n      <td>1.194556</td>\n      <td>0.546500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 5] Complete. Accuracy: 54.6500% | Time: 59.75s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 6/20] Starting...\n   Params: Rank=16, Alpha=96, LR=6.67e-06\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.684000</td>\n      <td>1.565699</td>\n      <td>0.366500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.501900</td>\n      <td>1.454975</td>\n      <td>0.519000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.410600</td>\n      <td>1.402946</td>\n      <td>0.526000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 6] Complete. Accuracy: 52.6000% | Time: 67.86s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 7/20] Starting...\n   Params: Rank=24, Alpha=32, LR=9.18e-06\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.676800</td>\n      <td>1.570889</td>\n      <td>0.352000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.526000</td>\n      <td>1.495999</td>\n      <td>0.493500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.457100</td>\n      <td>1.449582</td>\n      <td>0.514500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 7] Complete. Accuracy: 51.4500% | Time: 67.97s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 8/20] Starting...\n   Params: Rank=8, Alpha=96, LR=2.44e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.556500</td>\n      <td>1.400705</td>\n      <td>0.529000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.254100</td>\n      <td>1.179138</td>\n      <td>0.557000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.143400</td>\n      <td>1.136443</td>\n      <td>0.570000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 8] Complete. Accuracy: 57.0000% | Time: 58.99s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 9/20] Starting...\n   Params: Rank=4, Alpha=64, LR=2.57e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.034100</td>\n      <td>0.557694</td>\n      <td>0.814000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.434800</td>\n      <td>0.380228</td>\n      <td>0.876500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.259200</td>\n      <td>0.348866</td>\n      <td>0.886500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 9] Complete. Accuracy: 88.6500% | Time: 68.06s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 10/20] Starting...\n   Params: Rank=4, Alpha=16, LR=2.38e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.242800</td>\n      <td>0.763755</td>\n      <td>0.713000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.650800</td>\n      <td>0.577466</td>\n      <td>0.790000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.512600</td>\n      <td>0.541826</td>\n      <td>0.803500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 10] Complete. Accuracy: 80.3500% | Time: 59.51s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 11/20] Starting...\n   Params: Rank=24, Alpha=64, LR=6.43e-06\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.704100</td>\n      <td>1.587930</td>\n      <td>0.403000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.541500</td>\n      <td>1.513822</td>\n      <td>0.480000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.482900</td>\n      <td>1.476416</td>\n      <td>0.508500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 11] Complete. Accuracy: 50.8500% | Time: 67.99s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 12/20] Starting...\n   Params: Rank=16, Alpha=96, LR=4.09e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.508500</td>\n      <td>1.207721</td>\n      <td>0.551500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.072900</td>\n      <td>0.989769</td>\n      <td>0.647500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.941400</td>\n      <td>0.931567</td>\n      <td>0.673500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 12] Complete. Accuracy: 67.3500% | Time: 59.41s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 13/20] Starting...\n   Params: Rank=16, Alpha=64, LR=3.77e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.514600</td>\n      <td>1.238298</td>\n      <td>0.540500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.124100</td>\n      <td>1.051847</td>\n      <td>0.614500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.005600</td>\n      <td>0.992634</td>\n      <td>0.642000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 13] Complete. Accuracy: 64.2000% | Time: 59.39s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 14/20] Starting...\n   Params: Rank=4, Alpha=32, LR=4.73e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.950600</td>\n      <td>0.613170</td>\n      <td>0.777500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.488900</td>\n      <td>0.463691</td>\n      <td>0.849500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.350900</td>\n      <td>0.411424</td>\n      <td>0.864000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 14] Complete. Accuracy: 86.4000% | Time: 59.25s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 15/20] Starting...\n   Params: Rank=8, Alpha=96, LR=4.43e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.486300</td>\n      <td>1.212631</td>\n      <td>0.551500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.094000</td>\n      <td>1.004496</td>\n      <td>0.648500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.952800</td>\n      <td>0.951231</td>\n      <td>0.670000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 15] Complete. Accuracy: 67.0000% | Time: 59.41s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 16/20] Starting...\n   Params: Rank=2, Alpha=16, LR=2.72e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.613200</td>\n      <td>1.537963</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.461200</td>\n      <td>1.388392</td>\n      <td>0.523500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.328800</td>\n      <td>1.310183</td>\n      <td>0.533000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 16] Complete. Accuracy: 53.3000% | Time: 59.71s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 17/20] Starting...\n   Params: Rank=4, Alpha=8, LR=1.29e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.677200</td>\n      <td>1.591067</td>\n      <td>0.352000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.567300</td>\n      <td>1.558745</td>\n      <td>0.393000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.543600</td>\n      <td>1.551704</td>\n      <td>0.402500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 17] Complete. Accuracy: 40.2500% | Time: 59.61s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 18/20] Starting...\n   Params: Rank=16, Alpha=8, LR=7.38e-06\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.741100</td>\n      <td>1.656714</td>\n      <td>0.302500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.617100</td>\n      <td>1.594837</td>\n      <td>0.369000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.583100</td>\n      <td>1.583048</td>\n      <td>0.359000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 18] Complete. Accuracy: 35.9000% | Time: 59.39s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 19/20] Starting...\n   Params: Rank=8, Alpha=16, LR=1.84e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.601100</td>\n      <td>1.506445</td>\n      <td>0.498500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.385000</td>\n      <td>1.299311</td>\n      <td>0.533500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.261900</td>\n      <td>1.255522</td>\n      <td>0.541500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 19] Complete. Accuracy: 54.1500% | Time: 67.65s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 20/20] Starting...\n   Params: Rank=8, Alpha=32, LR=1.15e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.639100</td>\n      <td>1.549000</td>\n      <td>0.364500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.484300</td>\n      <td>1.431918</td>\n      <td>0.520500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.387500</td>\n      <td>1.376860</td>\n      <td>0.531500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 20] Complete. Accuracy: 53.1500% | Time: 67.60s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nExperiment Completed.\nTotal time taken to complete 20 experiments: 1273.541847229004 seconds\n\n========================================\nRESULTS SUMMARY\n========================================\nBest Accuracy: 88.6500% (Trial 9)\nMean Accuracy: 58.8950%\nStd Dev      : 14.7202%\nResults saved to random_search_results.csv\n\n========================================\nSTARTING ROBUSTNESS VERIFICATION (Top 5 Models)\n========================================\n\n>>> Verifying Rank 1: Trial 9 (Original Acc: 88.6500%)\n\n[Trial 9/20] Starting...\n   Params: Rank=4, Alpha=64, LR=2.57e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.023700</td>\n      <td>0.563455</td>\n      <td>0.796000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.431600</td>\n      <td>0.392285</td>\n      <td>0.872500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.222000</td>\n      <td>0.353402</td>\n      <td>0.888000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 9] Complete. Accuracy: 88.8000% | Time: 68.15s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 9/20] Starting...\n   Params: Rank=4, Alpha=64, LR=2.57e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.034900</td>\n      <td>0.585366</td>\n      <td>0.790000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.427100</td>\n      <td>0.390841</td>\n      <td>0.881500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.262300</td>\n      <td>0.354414</td>\n      <td>0.887500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 9] Complete. Accuracy: 88.7500% | Time: 68.05s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 9/20] Starting...\n   Params: Rank=4, Alpha=64, LR=2.57e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.022500</td>\n      <td>0.518615</td>\n      <td>0.814000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.426300</td>\n      <td>0.358665</td>\n      <td>0.882000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.252500</td>\n      <td>0.321658</td>\n      <td>0.892500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 9] Complete. Accuracy: 89.2500% | Time: 68.08s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"    -> Result: 88.9333% ± 0.2248%\n\n>>> Verifying Rank 2: Trial 14 (Original Acc: 86.4000%)\n\n[Trial 14/20] Starting...\n   Params: Rank=4, Alpha=32, LR=4.73e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.945100</td>\n      <td>0.595532</td>\n      <td>0.782000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.470100</td>\n      <td>0.419608</td>\n      <td>0.858000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.329500</td>\n      <td>0.395517</td>\n      <td>0.867500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 14] Complete. Accuracy: 86.7500% | Time: 59.18s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 14/20] Starting...\n   Params: Rank=4, Alpha=32, LR=4.73e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.956600</td>\n      <td>0.617547</td>\n      <td>0.772000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.482600</td>\n      <td>0.436747</td>\n      <td>0.844500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.342300</td>\n      <td>0.401312</td>\n      <td>0.863000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 14] Complete. Accuracy: 86.3000% | Time: 59.23s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 14/20] Starting...\n   Params: Rank=4, Alpha=32, LR=4.73e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.959000</td>\n      <td>0.549233</td>\n      <td>0.789500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.466700</td>\n      <td>0.405699</td>\n      <td>0.864000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.320400</td>\n      <td>0.373640</td>\n      <td>0.872500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 14] Complete. Accuracy: 87.2500% | Time: 59.19s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"    -> Result: 86.7667% ± 0.3880%\n\n>>> Verifying Rank 3: Trial 10 (Original Acc: 80.3500%)\n\n[Trial 10/20] Starting...\n   Params: Rank=4, Alpha=16, LR=2.38e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.238200</td>\n      <td>0.801110</td>\n      <td>0.711000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.661700</td>\n      <td>0.593086</td>\n      <td>0.781500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.512200</td>\n      <td>0.551850</td>\n      <td>0.797500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 10] Complete. Accuracy: 79.7500% | Time: 59.59s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 10/20] Starting...\n   Params: Rank=4, Alpha=16, LR=2.38e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.242000</td>\n      <td>0.782808</td>\n      <td>0.701500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.657800</td>\n      <td>0.573993</td>\n      <td>0.789000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.507100</td>\n      <td>0.537585</td>\n      <td>0.805000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 10] Complete. Accuracy: 80.5000% | Time: 59.70s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 10/20] Starting...\n   Params: Rank=4, Alpha=16, LR=2.38e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.214800</td>\n      <td>0.789051</td>\n      <td>0.698000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.659000</td>\n      <td>0.578376</td>\n      <td>0.788500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.513800</td>\n      <td>0.543039</td>\n      <td>0.807500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 10] Complete. Accuracy: 80.7500% | Time: 59.64s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"    -> Result: 80.3333% ± 0.4249%\n\n>>> Verifying Rank 4: Trial 3 (Original Acc: 67.7500%)\n\n[Trial 3/20] Starting...\n   Params: Rank=2, Alpha=16, LR=5.48e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.468300</td>\n      <td>1.179511</td>\n      <td>0.554000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.044600</td>\n      <td>0.969389</td>\n      <td>0.663000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.897400</td>\n      <td>0.904527</td>\n      <td>0.676000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 3] Complete. Accuracy: 67.6000% | Time: 68.49s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 3/20] Starting...\n   Params: Rank=2, Alpha=16, LR=5.48e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.472600</td>\n      <td>1.174805</td>\n      <td>0.561000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.038600</td>\n      <td>0.955257</td>\n      <td>0.662500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.899600</td>\n      <td>0.905026</td>\n      <td>0.675000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 3] Complete. Accuracy: 67.5000% | Time: 68.48s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 3/20] Starting...\n   Params: Rank=2, Alpha=16, LR=5.48e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.480500</td>\n      <td>1.174285</td>\n      <td>0.553000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.047600</td>\n      <td>0.959291</td>\n      <td>0.667000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.910300</td>\n      <td>0.898920</td>\n      <td>0.677000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 3] Complete. Accuracy: 67.7000% | Time: 68.52s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"    -> Result: 67.6000% ± 0.0816%\n\n>>> Verifying Rank 5: Trial 12 (Original Acc: 67.3500%)\n\n[Trial 12/20] Starting...\n   Params: Rank=16, Alpha=96, LR=4.09e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.487100</td>\n      <td>1.203470</td>\n      <td>0.551500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.081500</td>\n      <td>0.997863</td>\n      <td>0.658500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.945000</td>\n      <td>0.940771</td>\n      <td>0.670000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 12] Complete. Accuracy: 67.0000% | Time: 59.52s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 12/20] Starting...\n   Params: Rank=16, Alpha=96, LR=4.09e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.496100</td>\n      <td>1.190971</td>\n      <td>0.556500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.074600</td>\n      <td>0.985679</td>\n      <td>0.663500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.935800</td>\n      <td>0.941039</td>\n      <td>0.671500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 12] Complete. Accuracy: 67.1500% | Time: 59.64s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 12/20] Starting...\n   Params: Rank=16, Alpha=96, LR=4.09e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.501900</td>\n      <td>1.181110</td>\n      <td>0.553000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.062900</td>\n      <td>0.975160</td>\n      <td>0.660000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.927800</td>\n      <td>0.923455</td>\n      <td>0.671000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 12] Complete. Accuracy: 67.1000% | Time: 59.59s\n    -> Result: 67.0833% ± 0.0624%\n\nRobustness verification complete. Saved to robustness_verification_results.csv\n","output_type":"stream"}],"execution_count":11}]}