{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JJc7MbWr7Yyd",
        "outputId": "d1464d0c-df44-462f-9cd4-bc645a0a11bf"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxK1SCHr5tph"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "# Hugging Face Libraries\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    EvalPrediction\n",
        ")\n",
        "from peft import LoraConfig, TaskType, get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0YKohycIC7q"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Hyperparameter Search Space -> discrete sets\n",
        "LR_MIN, LR_MAX = 1e-5, 2e-4\n",
        "WARMUP_OPTIONS = [0.0, 0.06, 0.1]\n",
        "RANK_OPTIONS = [2, 4, 8, 16, 24]\n",
        "ALPHA_OPTIONS = [8, 16, 32, 64, 96]\n",
        "DROPOUT_OPTIONS = [0.0, 0.05, 0.1, 0.2]\n",
        "TARGET_MODULE_OPTIONS = [\n",
        "    [\"q_lin\", \"v_lin\"],\n",
        "    [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]\n",
        "]  # -> binary choice\n",
        "\n",
        "# Search bounds -> indices for discrete, actual values for continuous params\n",
        "MIN_BOUNDS = [LR_MIN, 0, 0, 0, 0, 0]\n",
        "MAX_BOUNDS = [\n",
        "    LR_MAX,\n",
        "    len(WARMUP_OPTIONS) - 0.01,\n",
        "    len(RANK_OPTIONS) - 0.01,\n",
        "    len(ALPHA_OPTIONS) - 0.01,\n",
        "    len(DROPOUT_OPTIONS) - 0.01,\n",
        "    len(TARGET_MODULE_OPTIONS) - 0.01\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xydWW_2EM-oE",
        "outputId": "f96bb540-bd64-4141-d78e-bed4926c7d60"
      },
      "outputs": [],
      "source": [
        "# Data Loading\n",
        "dataset = load_dataset('dair-ai/emotion')\n",
        "\n",
        "train_dataset = dataset['train'].shuffle(seed=42).select(range(3000)) # recommendation from cw brief to reduce compute time\n",
        "val_dataset = dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "58d2a23ae91540abad2051363bea688e",
            "a9626c2b024745c4a1a5e3492fa84ae9",
            "057a27bd2feb42efb6445af5b103162c",
            "6c365963fada4d778c2735150dd20b76",
            "a2b84f341ba741db95b58ae266e9a970",
            "2367d0740c29491fa375d1de37d16e9e",
            "6353e3cd57c04d8e9865a212d5369c4a",
            "3b526443ce95412f848b10738c23f223",
            "71e58b29c6a24333a49cff03d5cedd22",
            "db887a5c17bc4d55a1395c04140ae803",
            "908ff79c4458400caeb7ba1662de7175"
          ]
        },
        "id": "Y5i-YvKpNkj0",
        "outputId": "8d59a0a6-02cd-4838-b4c6-b352f58872ad"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_func(examples):\n",
        "  return tokenizer(\n",
        "      examples['text'],\n",
        "      truncation=True,\n",
        "      padding=True,\n",
        "      max_length=128\n",
        "  )\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_func, batched=True)\n",
        "tokenized_val = val_dataset.map(tokenize_func, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX6DqIdAS5DZ"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "\n",
        "def cleanup_memory():\n",
        "    \"\"\"Forcefully releases GPU memory\"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "def find_nearest(value, options):\n",
        "    return min(options, key=lambda x: abs(x - value)) # find nearest value from discrete set\n",
        "\n",
        "\n",
        "def random_individual() -> List[float]: # -> generate one vector of random (index based) hyperparams from options\n",
        "    return [\n",
        "        random.uniform(LR_MIN, LR_MAX), # LR -> continuous\n",
        "        random.uniform(0, len(WARMUP_OPTIONS) - 0.01), # warmup index\n",
        "        random.uniform(0, len(RANK_OPTIONS) - 0.01), # rank index\n",
        "        random.uniform(0, len(ALPHA_OPTIONS) - 0.01), # alpha index\n",
        "        random.uniform(0, len(DROPOUT_OPTIONS) - 0.01), # dropout index\n",
        "        random.uniform(0, len(TARGET_MODULE_OPTIONS) - 0.01) # modules index\n",
        "    ]\n",
        "\n",
        "\n",
        "# takes in an individual and repairs it -> need to change name later\n",
        "def repair_individual(pop_list: list) -> list:\n",
        "    \"\"\"Repair bounds and snap to valid discrete values\"\"\"\n",
        "    repaired = []\n",
        "    \n",
        "    # LR - continuous, just clip\n",
        "    repaired.append(float(np.clip(pop_list[0], MIN_BOUNDS[0], MAX_BOUNDS[0])))\n",
        "    \n",
        "    # discrete params - clip index then map to actual value\n",
        "    repaired.append(WARMUP_OPTIONS[int(np.clip(pop_list[1], MIN_BOUNDS[1], MAX_BOUNDS[1]))])\n",
        "    repaired.append(RANK_OPTIONS[int(np.clip(pop_list[2], MIN_BOUNDS[2], MAX_BOUNDS[2]))])\n",
        "    repaired.append(ALPHA_OPTIONS[int(np.clip(pop_list[3], MIN_BOUNDS[3], MAX_BOUNDS[3]))])\n",
        "    repaired.append(DROPOUT_OPTIONS[int(np.clip(pop_list[4], MIN_BOUNDS[4], MAX_BOUNDS[4]))])\n",
        "    repaired.append(int(np.clip(round(pop_list[5]), MIN_BOUNDS[5], MAX_BOUNDS[5])))\n",
        "    \n",
        "    return repaired"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbB1Z0Vs8NR8"
      },
      "outputs": [],
      "source": [
        "# NSGA2 Settings\n",
        "\n",
        "NGENS = 5\n",
        "CXPB = 0.9\n",
        "POPSIZE = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN4r4pGM3Ka7",
        "outputId": "58fb4605-a554-43ea-e083-c4dac542fc9e"
      },
      "outputs": [],
      "source": [
        "# DEAP imports\n",
        "%pip install deap\n",
        "from deap import base, benchmarks, algorithms, creator, tools\n",
        "from deap.benchmarks.tools import diversity, convergence, hypervolume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcrAkJVl8Pd7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "class NSGA2_HyperparameterOptimizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metric = evaluate.load(\"accuracy\")\n",
        "        self.pop_size = POPSIZE\n",
        "        self.ngens = NGENS\n",
        "        self.cxpb = CXPB\n",
        "\n",
        "\n",
        "\n",
        "        self.results = []\n",
        "        self.nfes = 0 # Number of function evaluations (trial_id)\n",
        "        self.best_solution = None\n",
        "        self.best_accuracy = 0.0\n",
        "        self.all_individuals = {}\n",
        "        \n",
        "        self.final_population = None\n",
        "        \n",
        "\n",
        "\n",
        "    def _compute_metrics(self, eval_pred: EvalPrediction):\n",
        "        preds, labels = eval_pred\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        return self.metric.compute(predictions=preds, references=labels)\n",
        "\n",
        "    def evaluate_individual(self, individual: List[float], trial_id: int):\n",
        "        \"\"\"Train model with given hyperparameters and return validation accuracy\"\"\"\n",
        "        params = repair_individual(individual)\n",
        "\n",
        "        print(f\"   > LR={params[0]:.2e}, Rank={params[2]}, \"\n",
        "              f\"Alpha={params[3]}, Dropout={params[4]}\")\n",
        "\n",
        "        # Load fresh model each time\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "          \"distilbert-base-uncased\",\n",
        "          num_labels=6 # for 6 emotions\n",
        "        )\n",
        "\n",
        "        peft_config = LoraConfig(\n",
        "            task_type=TaskType.SEQ_CLS,\n",
        "            r=params[2],\n",
        "            lora_alpha=params[3],\n",
        "            lora_dropout=params[4],\n",
        "            target_modules=[\"q_lin\", \"v_lin\"] if params[5]==0 else [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"],\n",
        "        )\n",
        "\n",
        "        peft_model = get_peft_model(model, peft_config)\n",
        "        args = TrainingArguments(\n",
        "            output_dir=f\"./results/trial_{trial_id}\",\n",
        "            learning_rate=params[0],\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=32,\n",
        "            num_train_epochs=3,\n",
        "            warmup_ratio=params[1],\n",
        "            logging_steps = 100,\n",
        "            weight_decay=0.01,\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"no\",\n",
        "            logging_strategy=\"epoch\",\n",
        "            seed=SEED + trial_id,\n",
        "            report_to=\"none\",\n",
        "            load_best_model_at_end=False\n",
        "        )\n",
        "\n",
        "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "        trainer = Trainer(\n",
        "            model=peft_model,\n",
        "            args=args,\n",
        "            train_dataset=tokenized_train,\n",
        "            data_collator=data_collator,\n",
        "            eval_dataset=tokenized_val,\n",
        "            compute_metrics=self._compute_metrics\n",
        "        )\n",
        "\n",
        "        num_trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "        print(f\"Number of trainable params: {num_trainable_params}\")\n",
        "\n",
        "        trainer.train()\n",
        "        eval_results = trainer.evaluate()\n",
        "        accuracy = eval_results[\"eval_accuracy\"]\n",
        "\n",
        "        # Cleanup\n",
        "        del model, peft_model, trainer\n",
        "        cleanup_memory()\n",
        "\n",
        "        return accuracy, num_trainable_params\n",
        "\n",
        "\n",
        "    def get_pareto_front(self, population=None):\n",
        "        \"\"\"\n",
        "        Extract the Pareto front (non-dominated solutions) from a population.\n",
        "        Uses DEAP's sortNondominated to get the first front.\n",
        "        \"\"\"\n",
        "        if population is None:\n",
        "            population = self.final_population\n",
        "        \n",
        "        if population is None:\n",
        "            raise ValueError(\"No population available. Run optimization first.\")\n",
        "        \n",
        "        # sortNondominated returns list of fronts; first_front_only=True gives just front 0\n",
        "        pareto_fronts = tools.sortNondominated(population, len(population), first_front_only=True)\n",
        "        return pareto_fronts[0]  # Return the first (Pareto-optimal) front\n",
        "\n",
        "\n",
        "    def run_optimization(self):\n",
        "        # Ensure creator classes exist\n",
        "        if not hasattr(creator, \"FitnessMulti\"):\n",
        "            creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0,-1.0))\n",
        "        if not hasattr(creator, \"Individual\"):\n",
        "            creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
        "\n",
        "        toolbox = base.Toolbox()\n",
        "        # Use initIterate so random_individual's list return value becomes the individual\n",
        "        toolbox.register(\"individual\", tools.initIterate, creator.Individual, random_individual)\n",
        "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "        pop = toolbox.population(n=self.pop_size)\n",
        "\n",
        "        toolbox.register(\"evaluate\", self.evaluate_individual)\n",
        "\n",
        "        toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "        toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.1)\n",
        "        toolbox.register(\"select\", tools.selNSGA2)\n",
        "\n",
        "        # the logbook stores the results\n",
        "        logbook = tools.Logbook()\n",
        "        # Add tracking columns to logbook\n",
        "        logbook.header = [\"gen\", \"evals\"] + [\"avg\", \"std\", \"min\", \"max\"]\n",
        "\n",
        "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "        stats.register(\"avg\", np.mean, axis=0)\n",
        "        stats.register(\"std\", np.std, axis=0)\n",
        "        stats.register(\"min\", np.min, axis=0)\n",
        "        stats.register(\"max\", np.max, axis=0)\n",
        "\n",
        "        def track_result(individual, fitness_val, gen):\n",
        "            params = repair_individual(individual)\n",
        "            param_dict = {\n",
        "              \"learning_rate\": params[0],\n",
        "              \"warmup_ratio\": params[1],\n",
        "              \"rank\": params[2],\n",
        "              \"alpha\": params[3],\n",
        "              \"dropout\": params[4],\n",
        "              \"target_modules\": [\"q_lin\", \"v_lin\"] if params[5]==0 else [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]\n",
        "            }\n",
        "\n",
        "            # Check for best solution\n",
        "            if fitness_val[0] > self.best_accuracy:\n",
        "                self.best_accuracy = fitness_val[0]\n",
        "                self.best_solution = param_dict\n",
        "\n",
        "            record = param_dict.copy()\n",
        "            record.update({\n",
        "                \"trial_id\": self.nfes,\n",
        "                \"generation\": gen,\n",
        "                \"accuracy\": fitness_val[0],\n",
        "                \"trainable_params\": fitness_val[1]\n",
        "            })\n",
        "            self.results.append(record)\n",
        "\n",
        "\n",
        "        # INITIALISATION\n",
        "        print(f\"Generation 0/{self.ngens}...\")\n",
        "        for i, ind in enumerate(pop):\n",
        "            self.nfes += 1\n",
        "            print(f\"Evaluating individual {i+1}/{self.pop_size} (Trial {self.nfes})...\")\n",
        "\n",
        "            fit = self.evaluate_individual(ind, self.nfes)\n",
        "            ind.fitness.values = fit\n",
        "            track_result(ind, fit, 0)\n",
        "\n",
        "            print(f\"Individual {i+1} acc: {fit[0]:.4f}, params: {fit[1]}\")\n",
        "\n",
        "        # adjust crowding distance (NSGA2 requirement)\n",
        "        pop = toolbox.select(pop, len(pop))\n",
        "\n",
        "        # get stats\n",
        "        record = stats.compile(pop)\n",
        "        logbook.record(gen=0, evals=len(pop), **record)\n",
        "        print(logbook.stream)\n",
        "        print(f\"   >> BEST so far: {self.best_accuracy:.4%} | Params: {self.best_solution}\")\n",
        "\n",
        "        # MAIN LOOP -> begin generational process\n",
        "        for generation in range(1, self.ngens):\n",
        "            print(f\"\\nGeneration {generation}/{self.ngens}...\")\n",
        "          # selTournamentDCD() - DCD -> DCD means Dominant based and Crowding Distance based\n",
        "            offspring = tools.selTournamentDCD(pop, len(pop))\n",
        "            offspring = [toolbox.clone(ind) for ind in offspring]\n",
        "\n",
        "            for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
        "                if random.random() <= self.cxpb:\n",
        "                    toolbox.mate(ind1, ind2)\n",
        "\n",
        "                toolbox.mutate(ind1)\n",
        "                toolbox.mutate(ind2)\n",
        "                del ind1.fitness.values, ind2.fitness.values\n",
        "\n",
        "            # in case of invalid fitness, re-evaluate individual's fitness\n",
        "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "\n",
        "            # Evaluate sequentially to track properly\n",
        "            for ind in invalid_ind:\n",
        "                self.nfes += 1\n",
        "                print(f\"Evaluating offspring (Trial {self.nfes})...\")\n",
        "                fit = self.evaluate_individual(ind, self.nfes)\n",
        "                ind.fitness.values = fit\n",
        "                track_result(ind, fit, generation)\n",
        "\n",
        "            # Selecting population to be passed to next generation\n",
        "            pop = toolbox.select(pop + offspring, self.pop_size)\n",
        "            record = stats.compile(pop)\n",
        "            logbook.record(gen=generation, evals=len(invalid_ind), **record)\n",
        "            print(logbook.stream) # being printed at end of every generation so as to evaluate\n",
        "            print(f\"   >> BEST so far: {self.best_accuracy:.4%} | Params: {self.best_solution}\")\n",
        "    \n",
        "\n",
        "        self.final_population = pop\n",
        "\n",
        "\n",
        "        try:\n",
        "            print(\"Final population hypervolume (measures quality on Paretto front)\", hypervolume(pop, [0.0, 2000000]) )\n",
        "        except Exception as e:\n",
        "            print(f\"Hypervolume calc failed: {e}\")\n",
        "        \n",
        "        return pop\n",
        "            \n",
        "            \n",
        "    def plot_pareto_front(self, filename: str = \"pareto_front.png\"):\n",
        "        \"\"\"\n",
        "        Visualize the Pareto front: accuracy vs trainable parameters.\n",
        "        \"\"\"\n",
        "        if self.final_population is None:\n",
        "            print(\"No final population available.\")\n",
        "            return\n",
        "        \n",
        "        pareto_front = self.get_pareto_front()\n",
        "        \n",
        "        # Extract fitness values\n",
        "        accuracies = [ind.fitness.values[0] for ind in pareto_front]\n",
        "        params = [ind.fitness.values[1] for ind in pareto_front]\n",
        "        \n",
        "        # Also plot all evaluated solutions for context\n",
        "        all_acc = [r['accuracy'] for r in self.results]\n",
        "        all_params = [r['trainable_params'] for r in self.results]\n",
        "        \n",
        "        plt.figure(figsize=(10, 7))\n",
        "        \n",
        "        # Plot all solutions (grey)\n",
        "        plt.scatter(all_params, all_acc, c='lightgray', alpha=0.5, \n",
        "                   label='All Evaluated', s=30)\n",
        "        \n",
        "        # Plot Pareto front (red, larger)\n",
        "        plt.scatter(params, accuracies, c='red', s=100, \n",
        "                   label='Pareto Front', edgecolors='black', zorder=5)\n",
        "        \n",
        "        # Connect Pareto front points with a line\n",
        "        sorted_pairs = sorted(zip(params, accuracies))\n",
        "        sorted_params, sorted_acc = zip(*sorted_pairs)\n",
        "        plt.plot(sorted_params, sorted_acc, 'r--', alpha=0.7, linewidth=2)\n",
        "        \n",
        "        plt.xlabel('Number of Trainable Parameters', fontsize=12)\n",
        "        plt.ylabel('Validation Accuracy', fontsize=12)\n",
        "        plt.title('NSGA-II Pareto Front: Accuracy vs Model Size', fontsize=14)\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(filename, dpi=150)\n",
        "        plt.close()\n",
        "        print(f\"Pareto front plot saved to {filename}\")\n",
        "\n",
        "\n",
        "    def save_pareto_front(self, filename: str = \"pareto_front.csv\"):\n",
        "        \"\"\"\n",
        "        Save the Pareto front individuals to a CSV file.\n",
        "        \"\"\"\n",
        "        if self.final_population is None:\n",
        "            print(\"No final population available. Run optimization first.\")\n",
        "            return None\n",
        "        \n",
        "        pareto_front = self.get_pareto_front()\n",
        "        \n",
        "        pareto_results = []\n",
        "        for i, ind in enumerate(pareto_front):\n",
        "            params = repair_individual(ind)\n",
        "            record = {\n",
        "                \"pareto_rank\": 0,  # All are on the first front\n",
        "                \"solution_id\": i,\n",
        "                \"learning_rate\": params[0],\n",
        "                \"warmup_ratio\": params[1],\n",
        "                \"rank\": params[2],\n",
        "                \"alpha\": params[3],\n",
        "                \"dropout\": params[4],\n",
        "                \"target_modules\": str([\"q_lin\", \"v_lin\"] if params[5]==0 \n",
        "                                      else [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]),\n",
        "                \"accuracy\": ind.fitness.values[0],\n",
        "                \"trainable_params\": ind.fitness.values[1],\n",
        "                # For convenience in plotting, also store objectives as error rate\n",
        "                \"error_rate\": 1.0 - ind.fitness.values[0]\n",
        "            }\n",
        "            pareto_results.append(record)\n",
        "        \n",
        "        df = pd.DataFrame(pareto_results)\n",
        "        # Sort by accuracy descending for readability\n",
        "        df = df.sort_values(\"accuracy\", ascending=False).reset_index(drop=True)\n",
        "        df.to_csv(filename, index=False)\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"PARETO FRONT SAVED: {filename}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Number of Pareto-optimal solutions: {len(pareto_front)}\")\n",
        "        print(f\"\\nPareto Front Summary:\")\n",
        "        print(f\"  Accuracy range: [{df['accuracy'].min():.4f}, {df['accuracy'].max():.4f}]\")\n",
        "        print(f\"  Params range: [{df['trainable_params'].min():.0f}, {df['trainable_params'].max():.0f}]\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        return df\n",
        "\n",
        "\n",
        "    def save_results(self, filename: str):\n",
        "        if not self.results:\n",
        "            print(\"No results to save.\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(self.results)\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"\\nResults saved to {filename}\")\n",
        "\n",
        "        # Print best result\n",
        "        if not df.empty:\n",
        "            best_run = df.loc[df['accuracy'].idxmax()]\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"BEST CONFIGURATION FOUND (by Accuracy):\")\n",
        "            print(\"=\"*60)\n",
        "            print(f\"Accuracy: {best_run['accuracy']:.4%}\")\n",
        "            print(f\"Trainable Params: {best_run['trainable_params']}\")\n",
        "            print(f\"Learning Rate: {best_run['learning_rate']:.2e}\")\n",
        "            print(f\"Warmup Ratio: {best_run['warmup_ratio']}\")\n",
        "            print(f\"Rank: {best_run['rank']}\")\n",
        "            print(f\"Alpha: {best_run['alpha']}\")\n",
        "            print(f\"Dropout: {best_run['dropout']}\")\n",
        "            print(f\"Target Modules: {best_run['target_modules']}\")\n",
        "            print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0KcM0htL8ec9",
        "outputId": "0abb53b9-408c-490a-94f0-6cb5fdf63da0"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    set_global_seed(SEED)\n",
        "\n",
        "    try:\n",
        "        # 2. Initialize NSGA2 Optimizer\n",
        "        optimizer = NSGA2_HyperparameterOptimizer()\n",
        "\n",
        "        # 3. Run Optimization\n",
        "        final_pop = optimizer.run_optimization()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nOptimization interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nCritical failure: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        # 4. Save results\n",
        "        if 'optimizer' in locals():\n",
        "            optimizer.save_results(\"nsga2_optimization_results.csv\")\n",
        "            \n",
        "            pareto_df = optimizer.save_pareto_front(\"pareto_front.csv\")\n",
        "            \n",
        "            optimizer.plot_pareto_front(\"pareto_front.png\")\n",
        "\n",
        "        cleanup_memory()\n",
        "        print(\"\\nProcess Complete.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "057a27bd2feb42efb6445af5b103162c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b526443ce95412f848b10738c23f223",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71e58b29c6a24333a49cff03d5cedd22",
            "value": 2000
          }
        },
        "2367d0740c29491fa375d1de37d16e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b526443ce95412f848b10738c23f223": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d2a23ae91540abad2051363bea688e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9626c2b024745c4a1a5e3492fa84ae9",
              "IPY_MODEL_057a27bd2feb42efb6445af5b103162c",
              "IPY_MODEL_6c365963fada4d778c2735150dd20b76"
            ],
            "layout": "IPY_MODEL_a2b84f341ba741db95b58ae266e9a970"
          }
        },
        "6353e3cd57c04d8e9865a212d5369c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c365963fada4d778c2735150dd20b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db887a5c17bc4d55a1395c04140ae803",
            "placeholder": "​",
            "style": "IPY_MODEL_908ff79c4458400caeb7ba1662de7175",
            "value": " 2000/2000 [00:00&lt;00:00, 3150.89 examples/s]"
          }
        },
        "71e58b29c6a24333a49cff03d5cedd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "908ff79c4458400caeb7ba1662de7175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2b84f341ba741db95b58ae266e9a970": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9626c2b024745c4a1a5e3492fa84ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2367d0740c29491fa375d1de37d16e9e",
            "placeholder": "​",
            "style": "IPY_MODEL_6353e3cd57c04d8e9865a212d5369c4a",
            "value": "Map: 100%"
          }
        },
        "db887a5c17bc4d55a1395c04140ae803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
