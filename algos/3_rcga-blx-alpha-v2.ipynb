{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:05:04.879449Z",
     "iopub.status.busy": "2025-11-29T01:05:04.878834Z",
     "iopub.status.idle": "2025-11-29T01:05:12.953071Z",
     "shell.execute_reply": "2025-11-29T01:05:12.952388Z",
     "shell.execute_reply.started": "2025-11-29T01:05:04.879422Z"
    },
    "id": "V5sbFKQwE63l",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install the libraries\n",
    "# !pip install transformers datasets peft torch accelerate evaluate\n",
    "!pip install  evaluate # '-q' flag to quietly install the packages without showing the output logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:05:15.443413Z",
     "iopub.status.busy": "2025-11-29T01:05:15.443101Z",
     "iopub.status.idle": "2025-11-29T01:05:44.031251Z",
     "shell.execute_reply": "2025-11-29T01:05:44.030609Z",
     "shell.execute_reply.started": "2025-11-29T01:05:15.443384Z"
    },
    "id": "2nUw5XEtZvPz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Import Hugging Face libraries\n",
    "import evaluate\n",
    "from datasets import load_dataset, Dataset, DatasetDict, IterableDataset, IterableDatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, EvalPrediction\n",
    "from peft import LoraConfig, TaskType, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:05:53.953605Z",
     "iopub.status.busy": "2025-11-29T01:05:53.953011Z",
     "iopub.status.idle": "2025-11-29T01:05:53.957458Z",
     "shell.execute_reply": "2025-11-29T01:05:53.956645Z",
     "shell.execute_reply.started": "2025-11-29T01:05:53.953578Z"
    },
    "id": "D7ZtuCpxHKxC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import the Python types\n",
    "from typing import List, Dict, Any, Tuple, cast, Optional\n",
    "\n",
    "from dataclasses import dataclass, asdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H7w-ySCrQhA"
   },
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:05:57.101859Z",
     "iopub.status.busy": "2025-11-29T01:05:57.101094Z",
     "iopub.status.idle": "2025-11-29T01:05:57.105502Z",
     "shell.execute_reply": "2025-11-29T01:05:57.104685Z",
     "shell.execute_reply.started": "2025-11-29T01:05:57.101833Z"
    },
    "id": "BZLhx4L0iHPT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TRAIN_SAMPLE_SIZE = 3000\n",
    "TOTAL_TRIALS = 20\n",
    "NUM_LABELS = 6\n",
    "MAX_LENGTH = 128\n",
    "MODEL = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCiniZH2949K"
   },
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:06:01.452511Z",
     "iopub.status.busy": "2025-11-29T01:06:01.451816Z",
     "iopub.status.idle": "2025-11-29T01:06:01.456934Z",
     "shell.execute_reply": "2025-11-29T01:06:01.456011Z",
     "shell.execute_reply.started": "2025-11-29T01:06:01.452488Z"
    },
    "id": "ZzBVjOBq949L",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Search Space (Discrete Options)\n",
    "\n",
    "LR_MIN, LR_MAX = 1e-5, 2e-4\n",
    "WARMUP_OPTIONS = [0.0, 0.03, 0.06, 0.1]\n",
    "\n",
    "WARMUP_OPTIONS = [0.0, 0.06, 0.1]\n",
    "\n",
    "RANK_OPTIONS = [2, 4, 8, 16, 24]\n",
    "\n",
    "ALPHA_OPTIONS = [8, 16, 32, 64, 96]\n",
    "\n",
    "DROPOUT_OPTIONS = [0.0, 0.05, 0.1, 0.2]\n",
    "\n",
    "TARGET_MODULE_OPTIONS = [\n",
    "    [\"q_lin\", \"v_lin\"],\n",
    "    [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:06:04.846574Z",
     "iopub.status.busy": "2025-11-29T01:06:04.846242Z",
     "iopub.status.idle": "2025-11-29T01:06:04.851555Z",
     "shell.execute_reply": "2025-11-29T01:06:04.850835Z",
     "shell.execute_reply.started": "2025-11-29T01:06:04.846543Z"
    },
    "id": "Cc-UISv9riuD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_global_seed(seed: int):\n",
    "  \"\"\"\n",
    "  Set the global seed for reproducibility.\n",
    "  \"\"\"\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  # Check if CUDA GPU is available\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:06:07.783698Z",
     "iopub.status.busy": "2025-11-29T01:06:07.783114Z",
     "iopub.status.idle": "2025-11-29T01:06:07.791742Z",
     "shell.execute_reply": "2025-11-29T01:06:07.791048Z",
     "shell.execute_reply.started": "2025-11-29T01:06:07.783671Z"
    },
    "id": "1hCQIogYtbph",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set_global_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:06:10.381249Z",
     "iopub.status.busy": "2025-11-29T01:06:10.380680Z",
     "iopub.status.idle": "2025-11-29T01:06:10.388624Z",
     "shell.execute_reply": "2025-11-29T01:06:10.387705Z",
     "shell.execute_reply.started": "2025-11-29T01:06:10.381225Z"
    },
    "id": "T4FMU-0B-FJV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Individual:\n",
    "  def __init__(self, genes: np.ndarray = None):\n",
    "    if genes is None:\n",
    "      self.genes = np.array([\n",
    "        np.random.uniform(LR_MIN, LR_MAX), # learning rate\n",
    "        np.random.randint(0, len(WARMUP_OPTIONS)), # warmup ratio\n",
    "        np.random.randint(0, len(RANK_OPTIONS)), # rank\n",
    "        np.random.randint(0, len(ALPHA_OPTIONS)), # alpha\n",
    "        np.random.randint(0, len(DROPOUT_OPTIONS)), # dropout\n",
    "        np.random.randint(0, len(TARGET_MODULE_OPTIONS)) # target modules\n",
    "      ], dtype=object)\n",
    "\n",
    "    else:\n",
    "      self.genes = genes.copy()\n",
    "\n",
    "    self.fitness = None\n",
    "\n",
    "  def decode(self):\n",
    "    # Continuous gene\n",
    "    self.learning_rate = self.genes[0]\n",
    "\n",
    "    warmup_index = np.clip(int(round(self.genes[1])), 0, len(WARMUP_OPTIONS) - 1)\n",
    "    self.warmup_ratio = WARMUP_OPTIONS[warmup_index]\n",
    "\n",
    "    rank_index = np.clip(int(round(self.genes[2])), 0, len(RANK_OPTIONS) - 1)\n",
    "    self.rank = RANK_OPTIONS[rank_index]\n",
    "\n",
    "    alpha_index = np.clip(int(round(self.genes[3])), 0, len(ALPHA_OPTIONS) - 1)\n",
    "    self.alpha = ALPHA_OPTIONS[alpha_index]\n",
    "\n",
    "    dropout_index = np.clip(int(round(self.genes[4])), 0, len(DROPOUT_OPTIONS) - 1)\n",
    "    self.dropout = DROPOUT_OPTIONS[dropout_index]\n",
    "\n",
    "    target_modules_index = np.clip(int(round(self.genes[5])), 0, len(TARGET_MODULE_OPTIONS) - 1)\n",
    "    self.target_modules = TARGET_MODULE_OPTIONS[target_modules_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:06:13.468504Z",
     "iopub.status.busy": "2025-11-29T01:06:13.467917Z",
     "iopub.status.idle": "2025-11-29T01:06:13.479878Z",
     "shell.execute_reply": "2025-11-29T01:06:13.478970Z",
     "shell.execute_reply.started": "2025-11-29T01:06:13.468478Z"
    },
    "id": "zPngxV1X949O",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for the parents\n",
    "def selection(population, num_parents):\n",
    "  parents = []\n",
    "  for i in range(num_parents):\n",
    "    idx1, idx2 = random.sample(range(len(population)), 2)\n",
    "    if population[idx1].fitness > population[idx2].fitness:\n",
    "      parents.append(population[idx1])\n",
    "    else:\n",
    "      parents.append(population[idx2])\n",
    "  return parents\n",
    "\n",
    "# for the children\n",
    "def crossover(parents, offspring_size):\n",
    "  offspring = []\n",
    "  for _ in range(offspring_size):\n",
    "    parent1, parent2 = random.sample(parents, 2)\n",
    "    crossover_point = random.randint(1, len(parent1.genes)-1)\n",
    "    child_genes = np.concatenate([parent1.genes[:crossover_point], parent2.genes[crossover_point:]])\n",
    "    offspring.append(Individual(child_genes))\n",
    "  return offspring\n",
    "\n",
    "# to create new children from current children (with different characteristics)\n",
    "# to create new children from current children (with different characteristics)\n",
    "def mutation(individual: Individual):\n",
    "  if random.random() < 0.1:\n",
    "    mutation_index = random.randint(0, len(individual.genes)-1)\n",
    "\n",
    "    if mutation_index == 0:\n",
    "      individual.genes[mutation_index] = np.random.uniform(LR_MIN, LR_MAX)\n",
    "\n",
    "    elif mutation_index == 1:\n",
    "      individual.genes[mutation_index] = np.random.randint(0, len(WARMUP_OPTIONS))\n",
    "\n",
    "    elif mutation_index == 2:\n",
    "      individual.genes[mutation_index] = np.random.randint(0, len(RANK_OPTIONS))\n",
    "\n",
    "    elif mutation_index == 3:\n",
    "      individual.genes[mutation_index] = np.random.randint(0, len(ALPHA_OPTIONS))\n",
    "\n",
    "    elif mutation_index == 4:\n",
    "      individual.genes[mutation_index] = np.random.randint(0, len(DROPOUT_OPTIONS))\n",
    "\n",
    "    elif mutation_index == 5:\n",
    "      individual.genes[mutation_index] = np.random.randint(0, len(TARGET_MODULE_OPTIONS))\n",
    "\n",
    "  return individual # Return the mutated individual, not the list\n",
    "\n",
    "\n",
    "def blx_alpha_crossover(parent1: Individual, parent2: Individual,\n",
    "                       min_bounds: np.ndarray, max_bounds: np.ndarray,\n",
    "                       alpha: float = 0.5) -> Individual:\n",
    "    \"\"\"\n",
    "    BLX-α crossover for continuous and index-based discrete variables.\n",
    "    \"\"\"\n",
    "    child_genes = np.zeros(len(parent1.genes), dtype=object)\n",
    "\n",
    "    for i in range(len(parent1.genes)):\n",
    "        g1, g2 = parent1.genes[i], parent2.genes[i]\n",
    "\n",
    "        if i == 0: # Learning rate is continuous\n",
    "            g1, g2 = float(g1), float(g2)\n",
    "            cmin, cmax = min(g1, g2), max(g1, g2)\n",
    "            interval = cmax - cmin\n",
    "\n",
    "            child_genes[i] = np.random.uniform(\n",
    "                cmin - alpha * interval,\n",
    "                cmax + alpha * interval\n",
    "            )\n",
    "        else:\n",
    "            g1, g2 = float(g1), float(g2)\n",
    "            cmin, cmax = min(g1, g2), max(g1, g2)\n",
    "            interval = cmax - cmin\n",
    "\n",
    "            child_genes[i] = np.random.uniform(\n",
    "                cmin - alpha * interval,\n",
    "                cmax + alpha * interval)\n",
    "\n",
    "    child_genes = np.clip(child_genes.astype(float), min_bounds.astype(float), max_bounds.astype(float))\n",
    "\n",
    "    for i in range(1, len(child_genes)):\n",
    "        child_genes[i] = int(round(child_genes[i]))\n",
    "\n",
    "    return Individual(child_genes.astype(object))\n",
    "\n",
    "\n",
    "\n",
    "# def fitness_function(individual):\n",
    "#   individual.decode()\n",
    "#   learning_rate = individual.learning_rate\n",
    "#   warmup_ratio = individual.warmup_ratio\n",
    "#   rank = individual.warmup_ratio\n",
    "#   alpha = individual.alpha\n",
    "#   dropout = individual.dropout\n",
    "#   target_modules = individual.target_modules\n",
    "\n",
    "#   print\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:06:29.193043Z",
     "iopub.status.busy": "2025-11-29T01:06:29.192742Z",
     "iopub.status.idle": "2025-11-29T01:06:29.200546Z",
     "shell.execute_reply": "2025-11-29T01:06:29.199660Z",
     "shell.execute_reply.started": "2025-11-29T01:06:29.193021Z"
    },
    "id": "XTsvM3x_7WE7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "  def __init__(self, model_name: str = MODEL):\n",
    "    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    self.dataset: Optional[Dict[str, Any]] = None\n",
    "\n",
    "  def prepare_data(self) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Loads the dataset and processes it.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the dataset is correctly loaded into the instance memory\n",
    "    if self.dataset is not None:\n",
    "        return self.dataset\n",
    "\n",
    "    print(\"Loading and processing data...\")\n",
    "\n",
    "    # Load full dataset\n",
    "    full_dataset = cast(DatasetDict, load_dataset(\"dair-ai/emotion\"))\n",
    "\n",
    "    # Use seed to ensure every run uses the SAME subset of data\n",
    "    train_subset = full_dataset[\"train\"].shuffle(seed=SEED).select(range(TRAIN_SAMPLE_SIZE))\n",
    "\n",
    "    # Private helper method for text embeddings\n",
    "    def _tokenize(examples):\n",
    "      return self.tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH\n",
    "      )\n",
    "\n",
    "    tokenized_train_dataset = train_subset.map(_tokenize, batched=True)\n",
    "    tokenized_validation_dataset = full_dataset[\"validation\"].map(_tokenize, batched=True)\n",
    "\n",
    "    self.dataset = {\n",
    "        \"train\": tokenized_train_dataset,\n",
    "        \"validation\": tokenized_validation_dataset,\n",
    "        \"tokenizer\": self.tokenizer,\n",
    "        \"num_labels\": NUM_LABELS\n",
    "    }\n",
    "\n",
    "    print(\"Data preparation complete.\")\n",
    "\n",
    "    return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:06:34.499785Z",
     "iopub.status.busy": "2025-11-29T01:06:34.498951Z",
     "iopub.status.idle": "2025-11-29T01:06:38.186036Z",
     "shell.execute_reply": "2025-11-29T01:06:38.185251Z",
     "shell.execute_reply.started": "2025-11-29T01:06:34.499755Z"
    },
    "id": "p9ZHBaIZ77fr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_manager = DataManager()\n",
    "data_bundle = data_manager.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWaZOwYu949P"
   },
   "source": [
    "# **RCGA-BLX-ALPHA Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:07:18.811498Z",
     "iopub.status.busy": "2025-11-29T01:07:18.811160Z",
     "iopub.status.idle": "2025-11-29T01:07:18.828182Z",
     "shell.execute_reply": "2025-11-29T01:07:18.827456Z",
     "shell.execute_reply.started": "2025-11-29T01:07:18.811472Z"
    },
    "id": "w5LAn0nG89dx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RCGAExperiment:\n",
    "    def __init__(self, data_bundle: Dict[str, Any]):\n",
    "        self.data = data_bundle\n",
    "        self.results: List[Dict[str, Any]] = []\n",
    "        self.metric = evaluate.load(\"accuracy\")\n",
    "        self.trial_counter = 0\n",
    "\n",
    "        # Bounds for the 6 genes\n",
    "        self.min_bounds = np.array([5e-6, 0.0, 2, 8, 0.0, 0.0])\n",
    "        self.max_bounds = np.array([5e-4, 0.1, 24, 96, 0.2, 1.0])\n",
    "\n",
    "    def _compute_metrics(self, eval_pred: EvalPrediction) -> Dict[str, float]:\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        result = self.metric.compute(predictions=predictions, references=labels)\n",
    "        return cast(Dict[str, float], result)\n",
    "\n",
    "    def _cleanup_memory(self):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    def train_model(self, trial_id: int, params: Individual) -> float:\n",
    "        print(f\"Params: LR={params.learning_rate:.2e}, Rank={params.rank}, Alpha={params.alpha}\")\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL, num_labels=self.data[\"num_labels\"]\n",
    "        )\n",
    "\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            r=params.rank,\n",
    "            lora_alpha=params.alpha,\n",
    "            lora_dropout=params.dropout,\n",
    "            target_modules=params.target_modules\n",
    "        )\n",
    "        model = get_peft_model(model, peft_config)\n",
    "\n",
    "        current_seed = SEED + trial_id\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            output_dir=f\"./results/rcga_trial_{trial_id}\",\n",
    "            learning_rate=params.learning_rate,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=3,\n",
    "            warmup_ratio=params.warmup_ratio,\n",
    "            weight_decay=0.01,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"no\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            seed=current_seed,\n",
    "            report_to=\"none\",\n",
    "            load_best_model_at_end=False,\n",
    "            optim=\"adamw_torch\"\n",
    "        )\n",
    "\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=self.data[\"tokenizer\"])\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=self.data[\"train\"],\n",
    "            eval_dataset=self.data[\"validation\"],\n",
    "            data_collator=data_collator,\n",
    "            compute_metrics=self._compute_metrics\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        eval_results = trainer.evaluate()\n",
    "\n",
    "        del model\n",
    "        del trainer\n",
    "        self._cleanup_memory()\n",
    "\n",
    "        return eval_results[\"eval_accuracy\"]\n",
    "\n",
    "    def fitness_function(self, individual: Individual) -> float:\n",
    "        self.trial_counter += 1\n",
    "\n",
    "        individual.decode()  # Decode the genes to set learning_rate, rank, etc.\n",
    "\n",
    "        try:\n",
    "            accuracy = self.train_model(self.trial_counter, individual)\n",
    "            print(f\"Accuracy: {accuracy:.4%}\")\n",
    "            return accuracy\n",
    "        except Exception as e:\n",
    "          print(f\"Error in Trial {self.trial_counter}: {e}\")\n",
    "          self._cleanup_memory()\n",
    "          return 0.0\n",
    "\n",
    "    def run_rcga(self, population_size: int = 20, generations: int = 5):\n",
    "        print(f\"Starting RCGA: {population_size} individuals, {generations} generations.\")\n",
    "\n",
    "        # 1. Initialization\n",
    "        population = [Individual() for _ in range(population_size)]\n",
    "\n",
    "        best_individual = None\n",
    "        best_fitness = -float('inf')\n",
    "\n",
    "        for gen in range(generations):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"GENERATION {gen + 1}/{generations}\")\n",
    "            print(f\"{'='*50}\")\n",
    "\n",
    "            # Evaluation\n",
    "            for i, individual in enumerate(population):\n",
    "                print(f\"\\n[Gen {gen+1}, Individual {i+1}/{population_size}]\")\n",
    "                individual.fitness = self.fitness_function(individual)\n",
    "\n",
    "                # tracking best solution\n",
    "                if individual.fitness > best_fitness:\n",
    "                    best_fitness = individual.fitness\n",
    "                    best_individual = Individual(individual.genes.copy())\n",
    "                    print(f\"NEW BEST FITNESS: {best_fitness:.4%}\")\n",
    "\n",
    "                # Log result\n",
    "                individual.decode()\n",
    "                record = {\n",
    "                    \"generation\": gen + 1,\n",
    "                    \"trial_id\": self.trial_counter,\n",
    "                    \"accuracy\": individual.fitness,\n",
    "                    \"learning_rate\": individual.learning_rate,\n",
    "                    \"warmup_ratio\": individual.warmup_ratio,\n",
    "                    \"rank\": individual.rank,\n",
    "                    \"alpha\": individual.alpha,\n",
    "                    \"dropout\": individual.dropout,\n",
    "                    \"target_modules\": str(individual.target_modules)\n",
    "                }\n",
    "                self.results.append(record)\n",
    "\n",
    "            # Stopping if last generation\n",
    "            if gen == generations - 1:\n",
    "                break\n",
    "\n",
    "            # Selection\n",
    "            num_parents = population_size // 2\n",
    "            parents = selection(population, num_parents)\n",
    "\n",
    "            # Crossover + Mutation\n",
    "            offspring = []\n",
    "            offspring.append(Individual(best_individual.genes.copy()))  # Elitism\n",
    "\n",
    "            while len(offspring) < population_size:\n",
    "                parent1, parent2 = random.sample(parents, 2)\n",
    "                child = blx_alpha_crossover(parent1, parent2, min_bounds=self.min_bounds,max_bounds=self.max_bounds, alpha=0.5)\n",
    "                mutation(child)\n",
    "                offspring.append(child)\n",
    "\n",
    "            # Replacing the population\n",
    "            population = offspring\n",
    "\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"RCGA OPTIMIZATION COMPLETE\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Best Fitness: {best_fitness:.4%}\")\n",
    "\n",
    "        return best_individual, best_fitness\n",
    "\n",
    "    def save_results(self, filename: str = \"rcga_results.csv\"):\n",
    "        \"\"\"Saves results to CSV and prints summary\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to save.\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(self.results)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "        best_run = df.loc[df['accuracy'].idxmax()]\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\"TOP RESULT:\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Accuracy: {best_run['accuracy']:.4%}\")\n",
    "        print(f\"Generation: {int(best_run['generation'])}\")\n",
    "        print(f\"Rank: {int(best_run['rank'])}, Alpha: {int(best_run['alpha'])}\")\n",
    "        print(f\"LR: {best_run['learning_rate']:.2e}\")\n",
    "        print(f\"Warmup: {best_run['warmup_ratio']}\")\n",
    "        print(f\"Dropout: {best_run['dropout']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T01:07:29.493037Z",
     "iopub.status.busy": "2025-11-29T01:07:29.492421Z",
     "iopub.status.idle": "2025-11-29T02:56:03.258003Z",
     "shell.execute_reply": "2025-11-29T02:56:03.257068Z",
     "shell.execute_reply.started": "2025-11-29T01:07:29.493005Z"
    },
    "id": "5lqsyHfB-uIJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create the Experiment\n",
    "import time\n",
    "\n",
    "experiment = RCGAExperiment(data_bundle)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the experiment\n",
    "experiment.run_rcga()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Initial training loop - time taken\", elapsed_time)\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "# Save the results\n",
    "experiment.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFbMGEfsUXjk"
   },
   "source": [
    "# getting top 5 best individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T03:03:18.236548Z",
     "iopub.status.busy": "2025-11-29T03:03:18.235859Z",
     "iopub.status.idle": "2025-11-29T03:03:18.254926Z",
     "shell.execute_reply": "2025-11-29T03:03:18.254153Z",
     "shell.execute_reply.started": "2025-11-29T03:03:18.236522Z"
    },
    "id": "2XGsD1LYs8Km",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "    def evaluate_top_solutions_with_seeds(self, num_top: int = 5, num_seeds: int = 3,\n",
    "                                            results_filename: str = \"top5_reeval_results.csv\"):\n",
    "          if not self.results:\n",
    "              print(\"No results available. Run the experiment first.\")\n",
    "              return\n",
    "    \n",
    "          print(f\"\\n{'='*60}\")\n",
    "          print(f\"EVALUATING TOP {num_top} SOLUTIONS WITH {num_seeds} DIFFERENT SEEDS\")\n",
    "          print(f\"{'='*60}\")\n",
    "    \n",
    "          # Convert results to DataFrame and get top solutions\n",
    "          df = pd.DataFrame(self.results)\n",
    "          df_sorted = df.sort_values('accuracy', ascending=False).head(num_top)\n",
    "    \n",
    "          final_results = []\n",
    "          detailed_results = []  # For CSV export\n",
    "    \n",
    "          for rank, (idx, row) in enumerate(df_sorted.iterrows(), 1):\n",
    "              individual = Individual()\n",
    "              individual.learning_rate = row['learning_rate']\n",
    "              individual.warmup_ratio = row['warmup_ratio']\n",
    "              individual.rank = row['rank']\n",
    "              individual.alpha = row['alpha']\n",
    "              individual.dropout = row['dropout']\n",
    "    \n",
    "              # parsing target_modules back from string\n",
    "              target_modules_str = row['target_modules']\n",
    "              if 'ffn' in target_modules_str:\n",
    "                  individual.target_modules = [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]\n",
    "              else:\n",
    "                  individual.target_modules = [\"q_lin\", \"v_lin\"]\n",
    "    \n",
    "              original_accuracy = row['accuracy']\n",
    "    \n",
    "              print(f\"\\n{'='*60}\")\n",
    "              print(f\"RANK {rank} - Original Accuracy: {original_accuracy:.4%}\")\n",
    "              print(f\"{'='*60}\")\n",
    "              print(f\"Params: LR={individual.learning_rate:.2e}, \"\n",
    "                    f\"Warmup={individual.warmup_ratio}, Rank={individual.rank}\")\n",
    "              print(f\"        Alpha={individual.alpha}, Dropout={individual.dropout}, \"\n",
    "                    f\"Modules={len(individual.target_modules)}\")\n",
    "              print(f\"\\nRunning {num_seeds} evaluations with different seeds...\")\n",
    "    \n",
    "              seed_accuracies = []\n",
    "    \n",
    "              for seed_run in range(num_seeds):\n",
    "                  # high trial_id offset to avoid collision with optimization trials\n",
    "                  trial_id = 10000 + (rank * 100) + seed_run\n",
    "    \n",
    "                  # using different seed for each run\n",
    "                  current_seed = SEED + trial_id\n",
    "    \n",
    "                  print(f\"  Seed run {seed_run + 1}/{num_seeds} (seed={current_seed})...\", end=\" \")\n",
    "    \n",
    "                  try:\n",
    "                      accuracy = self.train_model(trial_id, individual)\n",
    "                      seed_accuracies.append(accuracy)\n",
    "                      print(f\"Accuracy: {accuracy:.4%}\")\n",
    "    \n",
    "                      # Save detailed result\n",
    "                      detailed_results.append({\n",
    "                          'rank': rank,\n",
    "                          'seed_run': seed_run + 1,\n",
    "                          'seed': current_seed,\n",
    "                          'accuracy': accuracy,\n",
    "                          'learning_rate': individual.learning_rate,\n",
    "                          'warmup_ratio': individual.warmup_ratio,\n",
    "                          'rank_param': individual.rank,\n",
    "                          'alpha': individual.alpha,\n",
    "                          'dropout': individual.dropout,\n",
    "                          'target_modules': str(individual.target_modules),\n",
    "                          'original_accuracy': original_accuracy\n",
    "                      })\n",
    "    \n",
    "                  except Exception as e:\n",
    "                      print(f\"ERROR: {e}\")\n",
    "                      self._cleanup_memory()\n",
    "                      seed_accuracies.append(0.0)\n",
    "    \n",
    "              # calculating statistics\n",
    "              mean_acc = np.mean(seed_accuracies)\n",
    "              std_acc = np.std(seed_accuracies)\n",
    "              min_acc = np.min(seed_accuracies)\n",
    "              max_acc = np.max(seed_accuracies)\n",
    "    \n",
    "              print(f\"\\n  Results: {mean_acc:.4%} ± {std_acc:.4%}\")\n",
    "              print(f\"  Range: [{min_acc:.4%}, {max_acc:.4%}]\")\n",
    "              print(f\"  Individual runs: {[f'{acc:.4%}' for acc in seed_accuracies]}\")\n",
    "    \n",
    "              final_results.append({\n",
    "                  'rank': rank,\n",
    "                  'learning_rate': individual.learning_rate,\n",
    "                  'warmup_ratio': individual.warmup_ratio,\n",
    "                  'rank_param': individual.rank,\n",
    "                  'alpha': individual.alpha,\n",
    "                  'dropout': individual.dropout,\n",
    "                  'target_modules': str(individual.target_modules),\n",
    "                  'original_accuracy': original_accuracy,\n",
    "                  'mean_accuracy': mean_acc,\n",
    "                  'std_accuracy': std_acc,\n",
    "                  'min_accuracy': min_acc,\n",
    "                  'max_accuracy': max_acc,\n",
    "                  'seed_accuracies': seed_accuracies\n",
    "              })\n",
    "    \n",
    "          # saving detailed results to CSV in the exemplar format\n",
    "          if detailed_results:\n",
    "              df_detailed = pd.DataFrame(detailed_results)\n",
    "    \n",
    "              # Pivot to match the exemplar format - one row per rank with seed columns\n",
    "              df_pivot = df_detailed.pivot_table(\n",
    "                  index=['rank', 'learning_rate', 'warmup_ratio', 'rank_param', 'alpha',\n",
    "                         'dropout', 'target_modules', 'original_accuracy'],\n",
    "                  columns='seed_run',\n",
    "                  values='accuracy',\n",
    "                  aggfunc='first'\n",
    "              ).reset_index()\n",
    "    \n",
    "              # Rename the seed columns to match exemplar format\n",
    "              seed_columns = {i: f'seed_{i}_accuracy' for i in range(1, num_seeds + 1)}\n",
    "              df_pivot.rename(columns=seed_columns, inplace=True)\n",
    "    \n",
    "              # Add mean and std accuracy columns\n",
    "              seed_cols = [f'seed_{i}_accuracy' for i in range(1, num_seeds + 1)]\n",
    "              df_pivot['mean_accuracy'] = df_pivot[seed_cols].mean(axis=1)\n",
    "              df_pivot['std_accuracy'] = df_pivot[seed_cols].std(axis=1)\n",
    "    \n",
    "              # Rename columns to match exemplar exactly\n",
    "              df_pivot.rename(columns={'rank_param': 'rank_r'}, inplace=True)\n",
    "    \n",
    "              # Reorder columns to match exemplar format\n",
    "              column_order = ['rank', 'learning_rate', 'warmup_ratio', 'rank_r', 'alpha',\n",
    "                              'dropout', 'target_modules', 'original_accuracy', 'mean_accuracy',\n",
    "                              'std_accuracy'] + seed_cols\n",
    "              df_pivot = df_pivot[column_order]\n",
    "    \n",
    "              # Save to CSV\n",
    "              df_pivot.to_csv(results_filename, index=False)\n",
    "              print(f\"\\n{'='*60}\")\n",
    "              print(f\"Detailed results saved to {results_filename}\")\n",
    "    \n",
    "          # Print final summary\n",
    "          print(f\"\\n{'='*60}\")\n",
    "          print(f\"FINAL SUMMARY - TOP {num_top} SOLUTIONS\")\n",
    "          print(f\"{'='*60}\")\n",
    "    \n",
    "          for result in final_results:\n",
    "              print(f\"\\n{result['rank']}. Mean Accuracy: {result['mean_accuracy']:.4%} ± {result['std_accuracy']:.4%}\")\n",
    "              print(f\"   Original: {result['original_accuracy']:.4%}, \"\n",
    "                    f\"Range: [{result['min_accuracy']:.4%}, {result['max_accuracy']:.4%}]\")\n",
    "              print(f\"   LR: {result['learning_rate']:.2e}, Warmup: {result['warmup_ratio']}, \"\n",
    "                    f\"Rank: {result['rank_param']}\")\n",
    "              print(f\"   Alpha: {result['alpha']}, Dropout: {result['dropout']}, \"\n",
    "                    f\"Modules: {result['target_modules']}\")\n",
    "              runs_str = [f\"{acc:.4%}\" for acc in result['seed_accuracies']]\n",
    "              print(f\"   Runs: {runs_str}\")\n",
    "    \n",
    "          # identifying most robust solution (highest mean - std)\n",
    "          best_robust_idx = max(range(len(final_results)),\n",
    "                                key=lambda i: final_results[i]['mean_accuracy'] - final_results[i]['std_accuracy'])\n",
    "    \n",
    "          print(f\"\\n{'='*60}\")\n",
    "          print(\"MOST ROBUST SOLUTION (Mean - Std):\")\n",
    "          print(f\"{'='*60}\")\n",
    "          robust_result = final_results[best_robust_idx]\n",
    "          print(f\"Rank {robust_result['rank']}: {robust_result['mean_accuracy']:.4%} ± {robust_result['std_accuracy']:.4%}\")\n",
    "          print(f\"Robustness Score: {robust_result['mean_accuracy'] - robust_result['std_accuracy']:.4%}\")\n",
    "    \n",
    "          return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlrBtjWm8YqB"
   },
   "source": [
    "Evaluation of top 5 best individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T03:03:21.137043Z",
     "iopub.status.busy": "2025-11-29T03:03:21.136405Z",
     "iopub.status.idle": "2025-11-29T03:03:21.141054Z",
     "shell.execute_reply": "2025-11-29T03:03:21.140211Z",
     "shell.execute_reply.started": "2025-11-29T03:03:21.137019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import the types module\n",
    "import types\n",
    "\n",
    "# Bind the function to your existing experiment instance\n",
    "experiment.evaluate_top_solutions_with_seeds = types.MethodType(\n",
    "    evaluate_top_solutions_with_seeds, \n",
    "    experiment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T03:03:21.863893Z",
     "iopub.status.busy": "2025-11-29T03:03:21.863157Z",
     "iopub.status.idle": "2025-11-29T03:20:11.807484Z",
     "shell.execute_reply": "2025-11-29T03:20:11.806657Z",
     "shell.execute_reply.started": "2025-11-29T03:03:21.863858Z"
    },
    "id": "5DjaJszc8VFk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "top5_results = experiment.evaluate_top_solutions_with_seeds(\n",
    "    num_top=5,\n",
    "    num_seeds=3,\n",
    "    results_filename=\"top5_re_evaluation_results.csv\"\n",
    ")\n",
    "\n",
    "# Step 3: Access results\n",
    "best_robust = top5_results[0]\n",
    "print(f\"Best robust solution: {best_robust['mean_accuracy']:.4%} ± {best_robust['std_accuracy']:.4%}\")\n",
    "\n",
    "# experiment.plot_top5_reevaluation(top5_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
