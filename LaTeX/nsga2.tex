\section{Multi-objective Extension}

\noindent In this section, we explore the use of multi-objective evolutionary algorithms to determine the optimal trade-off boundary between validation accuracy and model complexity (measured by trainable parameters) for the LoRA adaptation of DistilBERT. We opted for the Non-dominated Sorted Genetic Algorithm II (NSGA-II), proposed by Deb et al.~\cite{nsga2}, as it provides computational efficiency in bi-objective problems through its fast non-dominated sorting mechanism ($O(MN^2)$). Furthermore, its elitist strategy means that optimal hyperparameter configurations are not lost through stochastic selection processes, but are rather passed onto the next generation. This ensures monotonic improvement in the Pareto front.

We use the same LoRA hyperparameter configurations as those in the other algorithms discussed in sections 2 \& 3\textbf{[CHECK]}, with the evolutionary parameters also unchanged (population size $P=20$ and generations $G=5$), matching the exact search space to ensure fairness. While the chosen single-objective algorithms focused on maximising validation accuracy, the complexity of these models did not contribute to selection pressure. In other words, these algorithms favour models with higher accuracy, regardless of over-parametrisation. For example, one LoRA configuration could produce an accuracy of 85.0\% with $rank=4$ and $\#trainable\_params=600,000$, resulting in low training cost. Another configuration could produce an accuracy of 85.1\% with $rank=24$ and $\#trainable\_params=2,000,000$, in which the training cost has significantly increased, but this cost is insignificant to single-objective algorithms and it will only select the model configuration with higher accuracy (85.1\% $>$ 85.0\%). Therefore, we can justify the need to introduce parameter efficiency as a primary optimisation goal alongside accuracy.

Figure ~\ref{fig:pareto_front} presents the Pareto front procured from the NSGA-II optimisation process, plotting validation accuracy against the number of trainable parameters.

\begin{figure}[H]
    \includegraphics[width=0.5\textwidth]{pareto_front.png}
    \caption{NSGA-II: Pareto Front}
    \label{fig:pareto_front}
\end{figure}

\noindent The red dots represent Pareto optimal solutions, which are characterised by having no further possibility of improving an objective without harming the other objectives~\cite{pareto_front} which, in this case, is the optimal trade-off between validation accuracy and number of trainable parameters. The grey dots on the other hand, represent the Pareto dominated solutions which were discovered during the optimisation process. These solutions are considered sub-optimal as they are overcome by non-dominated (Pareto front) solutions which achieve higher accuracies with the same amount of trainable parameters.

The front path displays a steep vertical ascent as the number of trainable parameters increase, until the path halts at a validation accuracy 90.2\% with 2.14M trainable parameters. The steepest ascent occurs when the parameters are $<0.75$M, inferring that the model is constrained by capacity. Evidently from the results, an increase of model size from 0.67M to 0.72M (8.2\% increase) training parameters provided a gain in accuracy--82.15\% to 87.75\% (5.6\% increase). This "High-Gain, Low-Cost" behaviour could demonstrate that LoRA configurations below 0.7M parameters (likely corresponding to $rank=2$) severely underfit the emotion dataset.

The knee point becomes visible at approximately 0.75M parameters, representing the most efficient trade-off in the search space as it approaches the peak accuracy. At this point the model size is roughly a third smaller than the largest configurations.

As the front path exceeds the knee point, the curve plateaus, converging to the maximum accuracy. During this stage, it can be observed that there requires a costly increase of nearly 40\% in number of training parameters to achieve a final 2\% gain in accuracy.

This analysis suggests that the LoRA hyperparameter optimisation problem benefits significantly from multi-objective optimisation algorithms. In contrast to single-objective optimisation algorithms, which inherently favour high-capacity models to secure marginal accuracy gains, multi-objective optimisation algorithms penalises high model-complexity. This strategy ensures smooth convergence towards the 'knee point' of the Pareto front, eventually achieving optimal efficiency by avoiding the selection of over-parametrised LoRA configurations. Ultimately, treating the number of training parameters and validation accuracy as conflicting objectives introduces a critical dimension of efficiency to the model selection process that would otherwise be ignored by single-objective algorithms.